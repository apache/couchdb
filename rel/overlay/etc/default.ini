[dreyfus]
name = {{clouseau_name}}
; Upgrading CouchDB will overwrite this file.
[vendor]
name = {{package_author_name}}

[couchdb]
uuid = {{uuid}}
database_dir = {{data_dir}}
view_index_dir = {{view_index_dir}}
; util_driver_dir =
; plugin_dir =
max_document_size = 67108864 ; 64 MB
os_process_timeout = 5000 ; 5 seconds. for view and external servers.
max_dbs_open = 500
delayed_commits = false
; Method used to compress everything that is appended to database and view index files, except
; for attachments (see the attachments section). Available methods are:
;
; none         - no compression
; snappy       - use google snappy, a very fast compressor/decompressor
; deflate_[N]  - use zlib's deflate, N is the compression level which ranges from 1 (fastest,
;                lowest compression ratio) to 9 (slowest, highest compression ratio)
file_compression = snappy
; Higher values may give better read performance due to less read operations
; and/or more OS page cache hits, but they can also increase overall response
; time for writes when there are many attachment write requests in parallel.
attachment_stream_buffer_size = 4096
; Default security object for databases if not explicitly set
; everyone - same as couchdb 1.0, everyone can read/write
; admin_only - only admins can read/write
; admin_local - sharded dbs on :5984 are read/write for everyone,
;               local dbs on :5986 are read/write for admins only
default_security = admin_local
; btree_chunk_size = 1279
; maintenance_mode = false
; stem_interactive_updates = true
; update_lru_on_read = true
; uri_file =

[cluster]
q=8
n=3
; placement = metro-dc-a:2,metro-dc-b:1

[chttpd]
port = {{cluster_port}}
bind_address = 0.0.0.0
backlog = 512
docroot = {{fauxton_root}}
socket_options = [{recbuf, 262144}, {sndbuf, 262144}, {nodelay, true}]

[database_compaction]
; larger buffer sizes can originate smaller files
doc_buffer_size = 524288 ; value in bytes
checkpoint_after = 5242880 ; checkpoint after every N bytes were written

[view_compaction]
; larger buffer sizes can originate smaller files
keyvalue_buffer_size = 2097152 ; value in bytes

[couch_peruser]
; If enabled, couch_peruser ensures that a private per-user database
; exists for each document in _users. These databases are writable only
; by the corresponding user. Databases are in the following form:
; userdb-{hex encoded username}
enable = false
; If set to true and a user is deleted, the respective database gets
; deleted as well.
delete_dbs = false

[httpd]
port = {{backend_port}}
bind_address = 0.0.0.0
authentication_handlers = {couch_httpd_oauth, oauth_authentication_handler}, {couch_httpd_auth, cookie_authentication_handler}, {couch_httpd_auth, default_authentication_handler}
default_handler = {couch_httpd_db, handle_request}
secure_rewrites = true
vhost_global_handlers = _utils, _uuids, _session, _oauth, _users
allow_jsonp = false
; Options for the MochiWeb HTTP server.
;server_options = [{backlog, 128}, {acceptor_pool_size, 16}]
; For more socket options, consult Erlang's module 'inet' man page.
;socket_options = [{recbuf, 262144}, {sndbuf, 262144}, {nodelay, true}]
socket_options = [{recbuf, 262144}, {sndbuf, 262144}]
enable_cors = false
; CouchDB can optionally enforce a maximum uri length;
; max_uri_length = 8000
; changes_timeout = 60000
; config_whitelist = 
; max_uri_length = 
; rewrite_limit = 100
; x_forwarded_host = X-Forwarded-Host
; x_forwarded_proto = X-Forwarded-Proto
; x_forwarded_ssl = X-Forwarded-Ssl

; [httpd_design_handlers]
; _view = 

; [ioq]
; concurrency = 10
; ratio = 0.01

[ssl]
port = 6984

; [chttpd_auth]
; authentication_db = _users

; [chttpd_auth_cache]
; max_lifetime = 600000
; max_objects = 
; max_size = 104857600

; [mem3]
; nodes_db = _nodes
; shard_cache_size = 25000
; shards_db = _dbs
; sync_concurrency = 10

; [fabric]
; all_docs_concurrency = 10
; changes_duration = 
; shard_timeout_factor = 2
; uuid_prefix_len = 7

; [rexi]
; buffer_count = 2000
; server_per_node = false

; [global_changes]
; max_event_delay = 25
; max_write_delay = 25
; update_db = true

; [view_updater]
; min_writer_items = 100
; min_writer_size = 16777216

[couch_httpd_auth]
authentication_db = _users
authentication_redirect = /_utils/session.html
require_valid_user = false
timeout = 600 ; number of seconds before automatic logout
auth_cache_size = 50 ; size is number of cache entries
allow_persistent_cookies = false ; set to true to allow persistent cookies
iterations = 10 ; iterations for password hashing
; min_iterations = 1
; max_iterations = 1000000000
; password_scheme = pbkdf2
; proxy_use_secret = false
; comma-separated list of public fields, 404 if empty
; public_fields =
; secret = 
; users_db_public = false

; CSP (Content Security Policy) Support for _utils
[csp]
enable = true
; header_value = default-src 'self'; img-src 'self'; font-src *; script-src 'self' 'unsafe-eval'; style-src 'self' 'unsafe-inline';

[cors]
credentials = false
; List of origins separated by a comma, * means accept all
; Origins must include the scheme: http://example.com
; You can’t set origins: * and credentials = true at the same time.
;origins = *
; List of accepted headers separated by a comma
; headers =
; List of accepted methods
; methods =

; Configuration for a vhost
;[cors:http://example.com]
; credentials = false
; List of origins separated by a comma
; Origins must include the scheme: http://example.com
; You can’t set origins: * and credentials = true at the same time.
;origins =
; List of accepted headers separated by a comma
; headers =
; List of accepted methods
; methods =

[couch_httpd_oauth]
; If set to 'true', oauth token and consumer secrets will be looked up
; in the authentication database (_users). These secrets are stored in
; a top level property named "oauth" in user documents. Example:
;     {
;         "_id": "org.couchdb.user:joe",
;         "type": "user",
;         "name": "joe",
;         "password_sha": "fe95df1ca59a9b567bdca5cbaf8412abd6e06121",
;         "salt": "4e170ffeb6f34daecfd814dfb4001a73"
;         "roles": ["foo", "bar"],
;         "oauth": {
;             "consumer_keys": {
;                 "consumerKey1": "key1Secret",
;                 "consumerKey2": "key2Secret"
;             },
;             "tokens": {
;                 "token1": "token1Secret",
;                 "token2": "token2Secret"
;             }
;         }
;     }
use_users_db = false

[query_servers]
javascript = {{prefix}}/bin/couchjs {{prefix}}/share/server/main.js
coffeescript = {{prefix}}/bin/couchjs {{prefix}}/share/server/main-coffee.js

; enable mango query engine
[native_query_servers]
query = {mango_native_proc, start_link, []}

; Changing reduce_limit to false will disable reduce_limit.
; If you think you're hitting reduce_limit with a "good" reduce function,
; please let us know on the mailing list so we can fine tune the heuristic.
[query_server_config]
; commit_freq = 5
reduce_limit = true
os_process_limit = 25
; os_process_idle_limit = 300
; os_process_soft_limit = 100

[daemons]
index_server={couch_index_server, start_link, []}
external_manager={couch_external_manager, start_link, []}
query_servers={couch_proc_manager, start_link, []}
vhosts={couch_httpd_vhost, start_link, []}
httpd={couch_httpd, start_link, []}
uuids={couch_uuids, start, []}
auth_cache={couch_auth_cache, start_link, []}
os_daemons={couch_os_daemons, start_link, []}
compaction_daemon={couch_compaction_daemon, start_link, []}
couch_peruser={couch_peruser, start_link, []}

[indexers]
couch_mrview = true

[httpd_global_handlers]
/ = {couch_httpd_misc_handlers, handle_welcome_req, <<"Welcome">>}
favicon.ico = {couch_httpd_misc_handlers, handle_favicon_req, "{{prefix}}/share/www"}

_utils = {couch_httpd_misc_handlers, handle_utils_dir_req, "{{prefix}}/share/www"}
_all_dbs = {couch_httpd_misc_handlers, handle_all_dbs_req}
_active_tasks = {couch_httpd_misc_handlers, handle_task_status_req}
_config = {couch_httpd_misc_handlers, handle_config_req}
_replicate = {couch_replicator_httpd, handle_req}
_uuids = {couch_httpd_misc_handlers, handle_uuids_req}
_restart = {couch_httpd_misc_handlers, handle_restart_req}
_stats = {couch_stats_httpd, handle_stats_req}
_session = {couch_httpd_auth, handle_session_req}
_oauth = {couch_httpd_oauth, handle_oauth_req}
_plugins = {couch_plugins_httpd, handle_req}
_system = {chttpd_misc, handle_system_req}

[httpd_db_handlers]
_all_docs = {couch_mrview_http, handle_all_docs_req}
_local_docs = {couch_mrview_http, handle_local_docs_req}
_design_docs = {couch_mrview_http, handle_design_docs_req}
_changes = {couch_httpd_db, handle_db_changes_req}
_compact = {couch_httpd_db, handle_compact_req}
_design = {couch_httpd_db, handle_design_req}
_temp_view = {couch_mrview_http, handle_temp_view_req}
_view_cleanup = {couch_mrview_http, handle_cleanup_req}

; The external module takes an optional argument allowing you to narrow it to a
; single script. Otherwise the script name is inferred from the first path section
; after _external's own path.
; _mypath = {couch_httpd_external, handle_external_req, <<"mykey">>}
; _external = {couch_httpd_external, handle_external_req}

[httpd_design_handlers]
_compact = {couch_mrview_http, handle_compact_req}
_info = {couch_mrview_http, handle_info_req}
_list = {couch_mrview_show, handle_view_list_req}
_rewrite = {couch_httpd_rewrite, handle_rewrite_req}
_show = {couch_mrview_show, handle_doc_show_req}
_update = {couch_mrview_show, handle_doc_update_req}
_view = {couch_mrview_http, handle_view_req}
_view_changes = {couch_mrview_http, handle_view_changes_req}

; enable external as an httpd handler, then link it with commands here.
; note, this api is still under consideration.
; [external]
; mykey = /path/to/mycommand

; Here you can setup commands for CouchDB to manage
; while it is alive. It will attempt to keep each command
; alive if it exits.
; [os_daemons]
; some_daemon_name = /path/to/script -with args
; [os_daemon_settings]
; max_retries = 3
; retry_time = 5


[uuids]
; Known algorithms:
;   random - 128 bits of random awesome
;     All awesome, all the time.
;   sequential - monotonically increasing ids with random increments
;     First 26 hex characters are random. Last 6 increment in
;     random amounts until an overflow occurs. On overflow, the
;     random prefix is regenerated and the process starts over.
;   utc_random - Time since Jan 1, 1970 UTC with microseconds
;     First 14 characters are the time in hex. Last 18 are random.
;   utc_id - Time since Jan 1, 1970 UTC with microseconds, plus utc_id_suffix string
;     First 14 characters are the time in hex. uuids/utc_id_suffix string value is appended to these.
algorithm = sequential
; The utc_id_suffix value will be appended to uuids generated by the utc_id algorithm.
; Replicating instances should have unique utc_id_suffix values to ensure uniqueness of utc_id ids.
utc_id_suffix =
# Maximum number of UUIDs retrievable from /_uuids in a single request
max_count = 1000

[attachments]
compression_level = 8 ; from 1 (lowest, fastest) to 9 (highest, slowest), 0 to disable compression
compressible_types = text/*, application/javascript, application/json, application/xml

[replicator]
; minimum time between a replicator job restart (milliseconds)
start_delay = 0
; random splay time between a replicator job restart (milliseconds)
start_splay = 0
; Maximum replicaton retry count can be a non-negative integer or "infinity".
max_replication_retry_count = 10
; More worker processes can give higher network throughput but can also
; imply more disk and network IO.
worker_processes = 4
; With lower batch sizes checkpoints are done more frequently. Lower batch sizes
; also reduce the total amount of used RAM memory.
worker_batch_size = 500
; Maximum number of HTTP connections per replication.
http_connections = 20
; HTTP connection timeout per replication.
; Even for very fast/reliable networks it might need to be increased if a remote
; database is too busy.
connection_timeout = 30000
; Request timeout
;request_timeout = infinity
; If a request fails, the replicator will retry it up to N times.
retries_per_request = 10
; Use checkpoints
;use_checkpoints = true
; Checkpoint interval
;checkpoint_interval = 30000
; Some socket options that might boost performance in some scenarios:
;       {nodelay, boolean()}
;       {sndbuf, integer()}
;       {recbuf, integer()}
;       {priority, integer()}
; See the `inet` Erlang module's man page for the full list of options.
socket_options = [{keepalive, true}, {nodelay, false}]
; Path to a file containing the user's certificate.
;cert_file = /full/path/to/server_cert.pem
; Path to file containing user's private PEM encoded key.
;key_file = /full/path/to/server_key.pem
; String containing the user's password. Only used if the private keyfile is password protected.
;password = somepassword
; Set to true to validate peer certificates.
verify_ssl_certificates = false
; File containing a list of peer trusted certificates (in the PEM format).
;ssl_trusted_certificates_file = /etc/ssl/certs/ca-certificates.crt
; Maximum peer certificate depth (must be set even if certificate validation is off).
ssl_certificate_max_depth = 3

[compaction_daemon]
; The delay, in seconds, between each check for which database and view indexes
; need to be compacted.
check_interval = 300
; If a database or view index file is smaller then this value (in bytes),
; compaction will not happen. Very small files always have a very high
; fragmentation therefore it's not worth to compact them.
min_file_size = 131072

[compactions]
; List of compaction rules for the compaction daemon.
; The daemon compacts databases and their respective view groups when all the
; condition parameters are satisfied. Configuration can be per database or
; global, and it has the following format:
;
; database_name = [ {ParamName, ParamValue}, {ParamName, ParamValue}, ... ]
; _default = [ {ParamName, ParamValue}, {ParamName, ParamValue}, ... ]
;
; Possible parameters:
;
; * db_fragmentation - If the ratio (as an integer percentage), of the amount
;                      of old data (and its supporting metadata) over the database
;                      file size is equal to or greater then this value, this
;                      database compaction condition is satisfied.
;                      This value is computed as:
;
;                           (file_size - data_size) / file_size * 100
;
;                      The data_size and file_size values can be obtained when
;                      querying a database's information URI (GET /dbname/).
;
; * view_fragmentation - If the ratio (as an integer percentage), of the amount
;                        of old data (and its supporting metadata) over the view
;                        index (view group) file size is equal to or greater then
;                        this value, then this view index compaction condition is
;                        satisfied. This value is computed as:
;
;                            (file_size - data_size) / file_size * 100
;
;                        The data_size and file_size values can be obtained when
;                        querying a view group's information URI
;                        (GET /dbname/_design/groupname/_info).
;
; * from _and_ to - The period for which a database (and its view groups) compaction
;                   is allowed. The value for these parameters must obey the format:
;
;                   HH:MM - HH:MM  (HH in [0..23], MM in [0..59])
;
; * strict_window - If a compaction is still running after the end of the allowed
;                   period, it will be canceled if this parameter is set to 'true'.
;                   It defaults to 'false' and it's meaningful only if the *period*
;                   parameter is also specified.
;
; * parallel_view_compaction - If set to 'true', the database and its views are
;                              compacted in parallel. This is only useful on
;                              certain setups, like for example when the database
;                              and view index directories point to different
;                              disks. It defaults to 'false'.
;
; Before a compaction is triggered, an estimation of how much free disk space is
; needed is computed. This estimation corresponds to 2 times the data size of
; the database or view index. When there's not enough free disk space to compact
; a particular database or view index, a warning message is logged.
;
; Examples:
;
; 1) [{db_fragmentation, "70%"}, {view_fragmentation, "60%"}]
;    The `foo` database is compacted if its fragmentation is 70% or more.
;    Any view index of this database is compacted only if its fragmentation
;    is 60% or more.
;
; 2) [{db_fragmentation, "70%"}, {view_fragmentation, "60%"}, {from, "00:00"}, {to, "04:00"}]
;    Similar to the preceding example but a compaction (database or view index)
;    is only triggered if the current time is between midnight and 4 AM.
;
; 3) [{db_fragmentation, "70%"}, {view_fragmentation, "60%"}, {from, "00:00"}, {to, "04:00"}, {strict_window, true}]
;    Similar to the preceding example - a compaction (database or view index)
;    is only triggered if the current time is between midnight and 4 AM. If at
;    4 AM the database or one of its views is still compacting, the compaction
;    process will be canceled.
;
; 4) [{db_fragmentation, "70%"}, {view_fragmentation, "60%"}, {from, "00:00"}, {to, "04:00"}, {strict_window, true}, {parallel_view_compaction, true}]
;    Similar to the preceding example, but a database and its views can be
;    compacted in parallel.
;
;_default = [{db_fragmentation, "70%"}, {view_fragmentation, "60%"}, {from, "23:00"}, {to, "04:00"}]

[log]
writer=file
file = var/log/couchdb/couch.log
; Set the log writer to use
; Current writers include:
;   stderr
;   file
;   syslog
; You can also specify a full module name
; here if you want to implement your own
; writer. See couch_log_writer.erl for
; more information on the (simple) API.
; writer = stderr

; Options for the file writer
; file = /path/to/couch.log
; write_buffer = size_in_bytes
; write_delay = time_in_milliseconds

; Options for the syslog writer
; syslog_host = remote host
; syslog_port = 514
; syslog_appid = couchdb
; syslog_facility = local2

; Possible logging levels (sorted by level):
;     none
;     emergency, emerg
;     alert
;     critical, crit
;     error, err
;     warning, warn
;     notice
;     info
;     debug
; Each controls how verbose logging will be. Higher level mean less log output.
; none level turns logging off
level = info
